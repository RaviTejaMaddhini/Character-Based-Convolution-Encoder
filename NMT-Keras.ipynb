{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding,Conv1D,MaxPooling1D,Dense\n",
    "from tensorflow.keras.activations import relu,sigmoid\n",
    "import tensorflow.keras.backend  as k\n",
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readlines(file):\n",
    "    with open(file,'r') as file:\n",
    "        data=file.readlines()\n",
    "        file.close()\n",
    "    data=[x.strip().lower() for x in data]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertIndicesToTensor(data):\n",
    "    val=np.array(data)\n",
    "    return k.variable(value=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Build_char_indexes(file):\n",
    "    with open(file,'r') as file:\n",
    "        data=file.readlines()\n",
    "        file.close()\n",
    "        \n",
    "    data=[x.strip() for x in data]\n",
    "    data=[re.sub(\"[^A-Za-z0-9\\s]+\",\" \",x) for x in data]\n",
    "    text=\" \".join(data).lower()\n",
    "    text=re.sub(\"\\s+\",\"\",text)\n",
    "    tokens=list(text)\n",
    "    tokens=np.unique(tokens)\n",
    "    char2id={}\n",
    "    id2char={}\n",
    "    tokens=sorted(tokens)\n",
    "    tokens=['<pad>','<u>']+tokens\n",
    "    for i,tok in enumerate(tokens):\n",
    "        char2id[tok]=i\n",
    "        id2char[i]=tok\n",
    "    index={}\n",
    "    index['char2id']=char2id\n",
    "    index['id2char']=id2char\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "def charPadding(sent_indices,char_max_len,index):\n",
    "    new_sents=[ [ word[:char_max_len] if len(word)>char_max_len else word+[index['char2id']['<pad>']]*(char_max_len-len(word))  for word in sent]for sent in sent_indices]\n",
    "    return new_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordPadding(sent_indices,char_max_len,index):\n",
    "    max_words=max([len(x) for x in sent_indices])\n",
    "    #new_sents=[sent if len(sent)==max_words else sent+[index['char2id']['<pad>']*char_max_len]*(max_words-len(sent)) for sent in sent_indices]\n",
    "    new_sents=[]\n",
    "    \n",
    "    for sent in sent_indices:\n",
    "        if len(sent)==max_words:\n",
    "            new_sents.append(sent)\n",
    "        else:\n",
    "            diff=max_words-len(sent)\n",
    "            ref=sent+[[index['char2id']['<pad>']]*char_max_len]*diff\n",
    "            new_sents.append(ref)\n",
    "    return new_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertSentstoCharIndices(sents,index):\n",
    "    sents=[re.sub(\"[^A-Za-z0-9\\s]+\",\" \",x) for x in sents]\n",
    "    sents=[re.sub(\"\\s+\",\" \",x).split(\" \") for x in sents]\n",
    "    idx=index['char2id']\n",
    "    output=[[[ idx[char] if char in idx.keys() else idx['<u>'] for char in word ]for word in sent]for sent in sents]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convOnCharacters(src_sent_indices):\n",
    "    print(\"No of sentences Fed : \",str(len(src_sent_indices)))\n",
    "    outputs=[]\n",
    "    for sent_ids in src_sent_indices:\n",
    "        sent_tensor=convertIndicesToTensor([sent_ids])\n",
    "        embeds=src_embeddings(sent_tensor)\n",
    "        embeds=tf.transpose(embeds,[0,1,3,2])\n",
    "        embeds=tf.squeeze(embeds,[0])\n",
    "        conv_output=conv_layer(embeds)\n",
    "        relu_output=relu(conv_output)\n",
    "        pool_out=max_pool_layer(relu_output)\n",
    "        pool_out=tf.squeeze(pool_out,[2])\n",
    "        outputs.append(pool_out)\n",
    "    output=tf.stack(outputs)\n",
    "    print(output.shape)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_file=\"/home/ravi/codeBase/Neural-Machine-Translation/Charcter-NMT/en_es_data/test_tiny.es\"\n",
    "tgt_file=\"/home/ravi/codeBase/Neural-Machine-Translation/Charcter-NMT/en_es_data/test_tiny.en\"\n",
    "MAX_WORD_LENGTH=21\n",
    "embedding_size=50\n",
    "src_index=Build_char_indexes(src_file)\n",
    "tgt_index=Build_char_indexes(tgt_file)\n",
    "\n",
    "src_sents=readlines(src_file)\n",
    "tgt_sents=readlines(tgt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_sent_indices=convertSentstoCharIndices(src_sents,src_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_sent_indices=charPadding(src_sent_indices,MAX_WORD_LENGTH,src_index)\n",
    "src_sent_indices=wordPadding(src_sent_indices,MAX_WORD_LENGTH,src_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "src_embeddings=Embedding(input_dim=len(src_index['char2id']),output_dim=embedding_size)\n",
    "conv_layer= Conv1D(filters=embedding_size,kernel_size=5,strides=1,use_bias=True,padding=\"valid\",data_format=\"channels_first\")\n",
    "max_pool_layer=MaxPooling1D(pool_size=17,strides=None,padding=\"valid\",data_format=\"channels_first\")\n",
    "highway_proj=Dense(embedding_size,activation=None,use_bias=True)\n",
    "highway_gate=Dense(embedding_size,activation=None,use_bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highwayLayer(conv_output):\n",
    "    proj_output=relu(highway_proj(conv_output))\n",
    "    gate_output=sigmoid(highway_gate(conv_output))\n",
    "    out=tf.math.multiply(proj_output,gate_output)+tf.math.multiply((1-gate_output),conv_output)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of sentences Fed :  4\n",
      "(4, 33, 50)\n",
      "(4, 33, 50)\n",
      "(4, 33, 50)\n"
     ]
    }
   ],
   "source": [
    "conv_output=convOnCharacters(src_sent_indices)\n",
    "highway_output=highwayLayer(conv_output)\n",
    "\n",
    "print(conv_output.shape)\n",
    "print(highway_output.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
